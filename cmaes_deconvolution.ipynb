{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMA-ES Approach in finding Dwell Time Profiles from NETSEQ Data\n",
    "\n",
    "## Problem\n",
    "\n",
    "The NET-seq signal $S(x) = D(x) \\cdot j(x)$, where $D(x)$ is the RNAP dwell time and $j(x)$ is the position-dependent flux. The TASEP simulation is a nonlinear forward model $F: D \\to S$. We seek $D^*$ minimizing $\\|F(D^*) - S_{\\text{exp}}\\|^2$.\n",
    "\n",
    "## Why CMA-ES?\n",
    "\n",
    "Richardson-Lucy iterative deconvolution fails because:\n",
    "1. The forward model is nonlinear (exclusion, Rho termination feedback)\n",
    "2. RL converges to a fixed point that is *worse* than the initial guess (see EXPLORATION.md)\n",
    "\n",
    "CMA-ES (Covariance Matrix Adaptation Evolution Strategy) is a gradient-free evolutionary optimizer that:\n",
    "- Does not require or approximate gradients\n",
    "- Handles noisy fitness functions (rank-based selection, not value-based)\n",
    "- Scales to ~1000D with sep-CMA-ES (diagonal covariance, O(n) complexity)\n",
    "- Naturally explores the loss landscape without the self-defeating feedback that breaks RL\n",
    "\n",
    "## Approach\n",
    "\n",
    "- Optimize in log-space: $\\theta(x) = \\log D(x)$ to enforce $D(x) > 0$\n",
    "- Use sep-CMA-ES (`CMA_diagonal=True`) for O(n) scaling to 1149 dimensions\n",
    "- Initial guess: $D^0 = S_{\\text{exp,norm}}$ (known near-optimal from RL analysis)\n",
    "- Small $\\sigma_0 = 0.1$ in log-space (~10% perturbation in D-space)\n",
    "- Objective: $\\text{MSE}(S_{\\text{exp,norm}},\\; S_{\\text{sim,norm}}(D))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cma version: 4.4.2\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import cma\n",
    "    print(f\"cma version: {cma.__version__}\")\n",
    "except ImportError:\n",
    "    import subprocess, sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"cma\"])\n",
    "    import cma\n",
    "    print(f\"Installed cma version: {cma.__version__}\")\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from netseq_tasep_fast import (\n",
    "    netseq_tasep_fast,\n",
    "    _load_gene_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Gene and simulation parameters ---\n",
    "GENE = \"insQ\"\n",
    "N_RUNS = 200          # TASEP runs per objective evaluation (noise/speed tradeoff)\n",
    "N_WORKERS = None      # None = os.cpu_count()\n",
    "\n",
    "# --- CMA-ES parameters ---\n",
    "SIGMA0 = 0.1         # Initial step size in log-space (~10% perturbation in D-space)\n",
    "MAX_GENERATIONS = 500 # Maximum CMA-ES generations\n",
    "POPSIZE = None        # None = pycma default (4 + floor(3*ln(n)) = 25 for n=1149)\n",
    "\n",
    "# --- Logging/checkpointing ---\n",
    "CHECKPOINT_EVERY = 25      # Save checkpoint every N generations\n",
    "CHECKPOINT_DIR = Path(\"cmaes_checkpoints\")\n",
    "DISPLAY_EVERY = 1          # Print progress every N generations\n",
    "\n",
    "# --- Reproducibility ---\n",
    "CMA_SEED = 67              # CMA-ES internal RNG seed\n",
    "SIM_BASE_SEED = 10_000     # Base seed for TASEP simulations (incremented per eval)\n",
    "\n",
    "# --- Resume from checkpoint (set to path to resume, or None to start fresh) ---\n",
    "RESUME_FROM = None          # e.g., \"cmaes_checkpoints/gen_0100.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene: insQ\n",
      "Gene length: 1149 bp\n",
      "KRutLoading: 0.13\n",
      "kRiboLoading: 0.0220\n",
      "\n",
      "log(D_init) stats: mean=-0.7579, std=1.0240\n",
      "D_init stats: mean=1.0000, min=0.1948, max=58.0638\n"
     ]
    }
   ],
   "source": [
    "# --- Load gene data ---\n",
    "base_params = _load_gene_parameters(GENE)\n",
    "S_exp_norm = base_params[\"RNAP_dwellTimeProfile\"].copy()  # Already normalized to mean=1\n",
    "gene_length = len(S_exp_norm)\n",
    "\n",
    "print(f\"Gene: {GENE}\")\n",
    "print(f\"Gene length: {gene_length} bp\")\n",
    "print(f\"KRutLoading: {base_params['KRutLoading']}\")\n",
    "print(f\"kRiboLoading: {base_params['kRiboLoading']:.4f}\")\n",
    "\n",
    "# Initial guess in log-space\n",
    "D_init = S_exp_norm.copy()\n",
    "theta_init = np.log(D_init)\n",
    "\n",
    "print(f\"\\nlog(D_init) stats: mean={theta_init.mean():.4f}, std={theta_init.std():.4f}\")\n",
    "print(f\"D_init stats: mean={D_init.mean():.4f}, min={D_init.min():.4f}, max={D_init.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function\n",
    "\n",
    "CMA-ES optimizes $\\theta(x) = \\log D(x)$. The objective:\n",
    "1. Exponentiates: $D = \\exp(\\theta)$\n",
    "2. Normalizes: $D_{\\text{norm}} = D / \\text{mean}(D)$\n",
    "3. Runs TASEP forward model (averaged over `N_RUNS` stochastic realizations)\n",
    "4. Normalizes output: $S_{\\text{sim,norm}} = S_{\\text{sim}} / \\text{mean}(S_{\\text{sim}})$\n",
    "5. Returns: $\\text{MSE} = \\frac{1}{L}\\sum_x (S_{\\text{exp}}(x) - S_{\\text{sim}}(x))^2$\n",
    "\n",
    "Each evaluation uses a unique deterministic seed to avoid overfitting to a particular noise realization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulations_with_dwell(dwell_profile, base_params, n_runs, base_seed, n_workers=None):\n",
    "    \"\"\"Run n_runs TASEP simulations with a custom dwell profile and return mean NETseq_sum.\"\"\"\n",
    "    params = dict(base_params)\n",
    "    params[\"RNAP_dwellTimeProfile\"] = dwell_profile\n",
    "\n",
    "    seeds = [base_seed + i for i in range(n_runs)]\n",
    "    if n_workers is None:\n",
    "        n_workers = os.cpu_count() or 1\n",
    "\n",
    "    def worker(s):\n",
    "        result = netseq_tasep_fast(params, seed=s)\n",
    "        return np.asarray(result[\"NETseq_sum\"], dtype=float)\n",
    "\n",
    "    if n_workers <= 1:\n",
    "        outputs = [worker(s) for s in seeds]\n",
    "    else:\n",
    "        with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "            outputs = list(executor.map(worker, seeds))\n",
    "\n",
    "    netseq_total = np.zeros_like(outputs[0], dtype=float)\n",
    "    for output in outputs:\n",
    "        netseq_total += output\n",
    "    return netseq_total / float(n_runs)\n",
    "\n",
    "\n",
    "# Global evaluation counter for deterministic seed management\n",
    "_eval_counter = 0\n",
    "\n",
    "def objective(theta):\n",
    "    \"\"\"CMA-ES objective: MSE between S_exp and TASEP(exp(theta)).\"\"\"\n",
    "    global _eval_counter\n",
    "    _eval_counter += 1\n",
    "\n",
    "    # Exponentiate to get D > 0, normalize to mean=1\n",
    "    D = np.exp(theta)\n",
    "    D_norm = D / np.mean(D)\n",
    "\n",
    "    # Run TASEP forward model with unique seed\n",
    "    eval_seed = SIM_BASE_SEED + _eval_counter * N_RUNS\n",
    "    S_sim = run_simulations_with_dwell(D_norm, base_params, N_RUNS, eval_seed, N_WORKERS)\n",
    "\n",
    "    # Normalize simulated signal\n",
    "    S_sim_mean = np.mean(S_sim)\n",
    "    if S_sim_mean > 0:\n",
    "        S_sim_norm = S_sim / S_sim_mean\n",
    "    else:\n",
    "        return 1e6  # Degenerate: no RNAPs survived\n",
    "\n",
    "    return np.mean((S_exp_norm - S_sim_norm) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Evaluation\n",
    "\n",
    "Evaluate the initial guess $D^0 = S_{\\text{exp,norm}}$ to establish starting fitness. This should match the RL iter-0 residual from `iterative_deconvolution.ipynb` (~3.48 RMS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE (D=S_exp_norm): 12.327057\n",
      "Baseline RMS residual:       3.5110\n",
      "Evaluation time:             1.15s\n",
      "\n",
      "Population size: 25\n",
      "Estimated time per generation: ~28.8s\n",
      "Estimated total for 500 generations: ~4.0 hours\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "baseline_mse = objective(theta_init)\n",
    "t_baseline = time.time() - t0\n",
    "\n",
    "baseline_rms = np.sqrt(baseline_mse)\n",
    "\n",
    "popsize_est = POPSIZE or (4 + int(3 * np.log(gene_length)))\n",
    "\n",
    "print(f\"Baseline MSE (D=S_exp_norm): {baseline_mse:.6f}\")\n",
    "print(f\"Baseline RMS residual:       {baseline_rms:.4f}\")\n",
    "print(f\"Evaluation time:             {t_baseline:.2f}s\")\n",
    "print(f\"\\nPopulation size: {popsize_est}\")\n",
    "print(f\"Estimated time per generation: ~{t_baseline * popsize_est:.1f}s\")\n",
    "print(f\"Estimated total for {MAX_GENERATIONS} generations: ~{t_baseline * popsize_est * MAX_GENERATIONS / 3600:.1f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMA-ES Optimization\n",
    "\n",
    "Using sep-CMA-ES (`CMA_diagonal=True`) for O(n) time and space complexity. At n=1149, full CMA-ES would require an O($n^3$) eigendecomposition per generation. Sep-CMA-ES stores only the diagonal and runs in O(n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint directory\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# CMA-ES options\n",
    "opts = {\n",
    "    'CMA_diagonal': True,       # sep-CMA-ES: diagonal covariance, O(n)\n",
    "    'seed': CMA_SEED,\n",
    "    'maxiter': MAX_GENERATIONS,\n",
    "    'verb_disp': 0,             # Suppress pycma's own printing\n",
    "    'verb_log': 0,              # Disable pycma file logging (we do our own)\n",
    "    'tolfun': 1e-8,             # Very tight: let it run until maxiter\n",
    "    'tolx': 1e-8,               # Very tight: let it run until maxiter\n",
    "}\n",
    "if POPSIZE is not None:\n",
    "    opts['popsize'] = POPSIZE\n",
    "\n",
    "# Initialize or resume\n",
    "if RESUME_FROM is not None:\n",
    "    with open(RESUME_FROM, 'rb') as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "    es = checkpoint['es']\n",
    "    history = checkpoint['history']\n",
    "    _eval_counter = checkpoint['eval_counter']\n",
    "    print(f\"Resumed from {RESUME_FROM}, generation {len(history['gen'])}\")\n",
    "else:\n",
    "    es = cma.CMAEvolutionStrategy(theta_init, SIGMA0, opts)\n",
    "    history = {\n",
    "        'gen': [],\n",
    "        'f_best': [],\n",
    "        'f_median': [],\n",
    "        'sigma': [],\n",
    "        'elapsed': [],\n",
    "        'theta_best': None,\n",
    "    }\n",
    "    _eval_counter = 0\n",
    "    print(f\"Starting fresh CMA-ES optimization\")\n",
    "\n",
    "print(f\"  Dimension: {es.N}\")\n",
    "print(f\"  Population size: {es.popsize}\")\n",
    "print(f\"  sigma0: {SIGMA0}\")\n",
    "print(f\"  n_runs per eval: {N_RUNS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "gen_count = len(history['gen'])\n",
    "\n",
    "try:\n",
    "    while not es.stop():\n",
    "        # Sample population\n",
    "        candidates = es.ask()\n",
    "\n",
    "        # Evaluate each candidate\n",
    "        fitnesses = [objective(x) for x in candidates]\n",
    "\n",
    "        # Update distribution\n",
    "        es.tell(candidates, fitnesses)\n",
    "\n",
    "        gen_count += 1\n",
    "        elapsed = time.time() - t_start\n",
    "\n",
    "        # Log\n",
    "        f_best = es.result.fbest\n",
    "        f_median = np.median(fitnesses)\n",
    "        sigma = es.sigma\n",
    "\n",
    "        history['gen'].append(gen_count)\n",
    "        history['f_best'].append(f_best)\n",
    "        history['f_median'].append(f_median)\n",
    "        history['sigma'].append(sigma)\n",
    "        history['elapsed'].append(elapsed)\n",
    "        history['theta_best'] = es.result.xbest.copy()\n",
    "\n",
    "        if gen_count % DISPLAY_EVERY == 0:\n",
    "            eta = elapsed / gen_count * (MAX_GENERATIONS - gen_count)\n",
    "            print(f\"  gen {gen_count:4d} | f_best={f_best:.6f} | f_med={f_median:.6f} | \"\n",
    "                  f\"sigma={sigma:.4f} | {elapsed:.0f}s | ETA {eta:.0f}s\")\n",
    "\n",
    "        # Checkpoint\n",
    "        if gen_count % CHECKPOINT_EVERY == 0:\n",
    "            ckpt_path = CHECKPOINT_DIR / f\"gen_{gen_count:04d}.pkl\"\n",
    "            with open(ckpt_path, 'wb') as f:\n",
    "                pickle.dump({\n",
    "                    'es': es,\n",
    "                    'history': history,\n",
    "                    'eval_counter': _eval_counter,\n",
    "                }, f)\n",
    "            print(f\"  >> Checkpoint saved: {ckpt_path}\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\n  Interrupted at generation {gen_count}. Saving checkpoint...\")\n",
    "    ckpt_path = CHECKPOINT_DIR / f\"gen_{gen_count:04d}_interrupted.pkl\"\n",
    "    with open(ckpt_path, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'es': es,\n",
    "            'history': history,\n",
    "            'eval_counter': _eval_counter,\n",
    "        }, f)\n",
    "    print(f\"  >> Checkpoint saved: {ckpt_path}\")\n",
    "\n",
    "total_time = time.time() - t_start\n",
    "stop_conditions = es.stop()\n",
    "print(f\"\\nDone in {total_time:.1f}s ({gen_count} generations)\")\n",
    "print(f\"Stop conditions: {stop_conditions}\")\n",
    "print(f\"Best MSE: {es.result.fbest:.6f} (RMS: {np.sqrt(es.result.fbest):.4f})\")\n",
    "print(f\"Baseline MSE was: {baseline_mse:.6f} (RMS: {baseline_rms:.4f})\")\n",
    "print(f\"Total evaluations: {_eval_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final state\n",
    "final_path = CHECKPOINT_DIR / \"final.pkl\"\n",
    "with open(final_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'es': es,\n",
    "        'history': history,\n",
    "        'eval_counter': _eval_counter,\n",
    "        'D_best': np.exp(es.result.xbest) / np.mean(np.exp(es.result.xbest)),\n",
    "        'S_exp_norm': S_exp_norm,\n",
    "        'gene': GENE,\n",
    "    }, f)\n",
    "print(f\"Final state saved to {final_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "gens = np.array(history['gen'])\n",
    "\n",
    "# Best objective\n",
    "axes[0].semilogy(gens, history['f_best'], '-', color='steelblue', lw=1)\n",
    "axes[0].axhline(baseline_mse, color='gray', ls='--', lw=1, label=f'Baseline: {baseline_mse:.4f}')\n",
    "axes[0].set_xlabel('Generation')\n",
    "axes[0].set_ylabel('Best MSE (log scale)')\n",
    "axes[0].set_title('Objective convergence')\n",
    "axes[0].legend(fontsize=8)\n",
    "\n",
    "# Best vs median\n",
    "axes[1].semilogy(gens, history['f_median'], '-', color='tab:orange', lw=0.8, alpha=0.7, label='Median')\n",
    "axes[1].semilogy(gens, history['f_best'], '-', color='steelblue', lw=1, label='Best')\n",
    "axes[1].set_xlabel('Generation')\n",
    "axes[1].set_ylabel('MSE (log scale)')\n",
    "axes[1].set_title('Best vs median fitness')\n",
    "axes[1].legend(fontsize=8)\n",
    "\n",
    "# Sigma\n",
    "axes[2].plot(gens, history['sigma'], '-', color='tab:green', lw=1)\n",
    "axes[2].set_xlabel('Generation')\n",
    "axes[2].set_ylabel('sigma')\n",
    "axes[2].set_title('Step-size adaptation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results: High-Fidelity Evaluation\n",
    "\n",
    "Re-evaluate the best $D^*$ and the baseline with 300 runs for a clean comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best D*\n",
    "theta_best = es.result.xbest\n",
    "D_best = np.exp(theta_best)\n",
    "D_best_norm = D_best / np.mean(D_best)\n",
    "\n",
    "# High-fidelity evaluation (300 runs)\n",
    "print(\"Running high-fidelity evaluation of D* (300 runs)...\")\n",
    "t0 = time.time()\n",
    "S_sim_best = run_simulations_with_dwell(D_best_norm, base_params, 300, 99999, N_WORKERS)\n",
    "S_sim_best_norm = S_sim_best / np.mean(S_sim_best)\n",
    "print(f\"  Done in {time.time() - t0:.1f}s\")\n",
    "\n",
    "print(\"Running high-fidelity baseline (300 runs)...\")\n",
    "t0 = time.time()\n",
    "S_sim_baseline = run_simulations_with_dwell(S_exp_norm, base_params, 300, 88888, N_WORKERS)\n",
    "S_sim_baseline_norm = S_sim_baseline / np.mean(S_sim_baseline)\n",
    "print(f\"  Done in {time.time() - t0:.1f}s\")\n",
    "\n",
    "mse_best = np.mean((S_exp_norm - S_sim_best_norm) ** 2)\n",
    "mse_baseline = np.mean((S_exp_norm - S_sim_baseline_norm) ** 2)\n",
    "\n",
    "print(f\"\\nHigh-fidelity MSE comparison:\")\n",
    "print(f\"  Baseline (D=S_exp):  MSE={mse_baseline:.6f}, RMS={np.sqrt(mse_baseline):.4f}\")\n",
    "print(f\"  CMA-ES optimized D*: MSE={mse_best:.6f}, RMS={np.sqrt(mse_best):.4f}\")\n",
    "if mse_baseline > 0:\n",
    "    print(f\"  Improvement: {(1 - mse_best / mse_baseline) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.arange(1, gene_length + 1)\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), gridspec_kw={'height_ratios': [3, 3, 1]})\n",
    "\n",
    "# S_exp vs S_sim(D*) vs S_sim(baseline)\n",
    "axes[0].plot(pos, S_exp_norm, lw=0.6, color='black', label='S_exp (normalized)', alpha=0.8)\n",
    "axes[0].plot(pos, S_sim_best_norm, lw=0.6, color='tab:blue', label='S_sim(D*) CMA-ES', alpha=0.8)\n",
    "axes[0].plot(pos, S_sim_baseline_norm, lw=0.6, color='tab:red', label='S_sim(D=S_exp) baseline', alpha=0.5)\n",
    "axes[0].set_ylabel('Normalized signal')\n",
    "axes[0].set_title(f'{GENE}: Experimental vs Simulated NET-seq signal')\n",
    "axes[0].legend(fontsize=9)\n",
    "\n",
    "# D* vs S_exp\n",
    "axes[1].plot(pos, S_exp_norm, lw=0.5, color='black', label='S_exp (naive D)', alpha=0.6)\n",
    "axes[1].plot(pos, D_best_norm, lw=0.5, color='tab:blue', label='D* (CMA-ES optimized)')\n",
    "axes[1].set_ylabel('Normalized dwell time')\n",
    "axes[1].set_title('Dwell time: naive vs optimized')\n",
    "axes[1].legend(fontsize=9)\n",
    "\n",
    "# Point-wise residual\n",
    "axes[2].plot(pos, S_exp_norm - S_sim_best_norm, lw=0.5, color='tab:blue', alpha=0.7, label='CMA-ES')\n",
    "axes[2].plot(pos, S_exp_norm - S_sim_baseline_norm, lw=0.5, color='tab:red', alpha=0.4, label='Baseline')\n",
    "axes[2].axhline(0, color='gray', ls='-', lw=0.5)\n",
    "axes[2].set_xlabel('Position (bp)')\n",
    "axes[2].set_ylabel('Residual')\n",
    "axes[2].set_title('Point-wise residual (S_exp - S_sim)')\n",
    "axes[2].legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implied Flux Profile\n",
    "\n",
    "If $S(x) = D(x) \\cdot j(x)$ and we have $D^*$, then the implied flux is $j^*(x) = S_{\\text{sim}}^*(x) / D^*(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implied flux\n",
    "j_implied = S_sim_best / np.maximum(D_best_norm, 1e-6)\n",
    "j_implied_norm = j_implied / np.max(j_implied[:100])  # Normalize to ~1 at 5' end\n",
    "\n",
    "# Analytical flux shape for comparison (Eq. M3)\n",
    "ell_0 = 35 + 50  # ell_RNAP + ell_min = 85 bp\n",
    "x = np.arange(1, gene_length + 1, dtype=float)\n",
    "j_analytical = np.ones(gene_length)\n",
    "mask = x > ell_0\n",
    "j_analytical[mask] = np.exp(-base_params['KRutLoading'] / (2 * gene_length) * (x[mask] - ell_0) ** 2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(pos, j_implied_norm, lw=0.8, color='tab:blue', label='j*(x) implied from CMA-ES')\n",
    "ax.plot(pos, j_analytical, lw=1.5, color='tab:red', ls='--', label='j_analytical (Eq. M3, Gaussian approx)')\n",
    "ax.set_xlabel('Position (bp)')\n",
    "ax.set_ylabel('Flux j(x) / j(0)')\n",
    "ax.set_title(f'{GENE}: Implied RNAP flux profile')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correction Factor: D* / S_exp\n",
    "\n",
    "The ratio $D^*(x) / S_{\\text{exp}}(x)$ reveals the systematic correction CMA-ES applied. Under constant flux this ratio would be 1 everywhere. Deviations reveal flux contamination in the naive estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction = D_best_norm / np.maximum(S_exp_norm, 1e-6)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].plot(pos, correction, lw=0.6, color='tab:purple')\n",
    "axes[0].axhline(1.0, color='gray', ls='--', lw=0.5)\n",
    "axes[0].set_xlabel('Position (bp)')\n",
    "axes[0].set_ylabel('D* / S_exp')\n",
    "axes[0].set_title('Correction factor (D* / S_exp)')\n",
    "\n",
    "# Smoothed version\n",
    "window = 25\n",
    "correction_smooth = np.convolve(correction, np.ones(window) / window, mode='same')\n",
    "axes[1].plot(pos, correction_smooth, lw=1.5, color='tab:purple', label=f'{window}-bp rolling mean')\n",
    "axes[1].plot(pos, 1.0 / j_analytical, lw=1.5, color='tab:red', ls='--', label='1/j_analytical (predicted)')\n",
    "axes[1].axhline(1.0, color='gray', ls='--', lw=0.5)\n",
    "axes[1].set_xlabel('Position (bp)')\n",
    "axes[1].set_ylabel('D* / S_exp (smoothed)')\n",
    "axes[1].set_title('Smoothed correction vs analytical prediction')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netseq-tasep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
